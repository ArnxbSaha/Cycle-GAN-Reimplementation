{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgF419g3p8Xe"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QK9lYFywpkI_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.linalg import sqrtm\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "import torch.autograd as autograd\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "from IPython.display import clear_output\n",
        "import itertools\n",
        "import glob\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from skimage import io\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6XvTTEKqVP6"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-swof_Eqhks"
      },
      "source": [
        "# Neural Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOP2lSY7qnOw"
      },
      "outputs": [],
      "source": [
        "# RESIDUAL BLOCK\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channel):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channel, in_channel, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.InstanceNorm2d(in_channel),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_channel, in_channel, kernel_size=3, stride=1, padding=0, bias=False),\n",
        "            nn.InstanceNorm2d(in_channel),\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(x + self.block(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aABVfhHqv0D"
      },
      "outputs": [],
      "source": [
        "# GENERATOR BLOCK\n",
        "\n",
        "class GeneratorResNet(nn.Module):\n",
        "    def __init__(self, input_shape, num_residual_blocks):\n",
        "        super().__init__()\n",
        "\n",
        "        channels = input_shape[0]\n",
        "        out_channels = 64\n",
        "\n",
        "        model = [\n",
        "            nn.ReflectionPad2d(channels),\n",
        "            nn.Conv2d(channels, out_channels, kernel_size=7, padding=0),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        in_channels = out_channels\n",
        "\n",
        "        for _ in range(2):\n",
        "            out_channels *= 2\n",
        "            model += [\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_channels = out_channels\n",
        "\n",
        "        for _ in range(num_residual_blocks):\n",
        "            model += [ResidualBlock(out_channels)]\n",
        "\n",
        "        # upsampling\n",
        "        for _ in range(2):\n",
        "            out_channels //= 2\n",
        "            model += [\n",
        "                nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            in_channels = out_channels\n",
        "\n",
        "        model += [\n",
        "            nn.ReflectionPad2d(channels),\n",
        "            nn.Conv2d(out_channels, channels, kernel_size=7, padding=0),\n",
        "            nn.Tanh(),\n",
        "        ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UyDI-t9rZds"
      },
      "outputs": [],
      "source": [
        "# DISCRIMINATOR BLOCK\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        channels, height, width = input_shape\n",
        "        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n",
        "\n",
        "        def discriminator_block(in_channels, out_channels, normalize=True):\n",
        "            layers = []\n",
        "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1))\n",
        "            if normalize:\n",
        "                layers.append(nn.InstanceNorm2d(out_channels))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return nn.Sequential(*layers)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            discriminator_block(channels, out_channels=64, normalize=False),\n",
        "            discriminator_block(64, out_channels=128),\n",
        "            discriminator_block(128, out_channels=256),\n",
        "            discriminator_block(256, out_channels=512),\n",
        "            nn.ZeroPad2d((1, 0, 1, 0)),\n",
        "            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4, padding=1)\n",
        "        )\n",
        "       \n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTF23ZalsQTF"
      },
      "source": [
        "# DataPreprocessing and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cojvVMf4sV9b"
      },
      "outputs": [],
      "source": [
        "#dataloader and rgb confirmation\n",
        "\n",
        "def convert_to_rgb(image):\n",
        "    rgb_image = Image.new(\"RGB\", image.size)\n",
        "    rgb_image.paste(image)\n",
        "    return rgb_image\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\"):\n",
        "        self.transform = transforms.Compose(transforms_) if transforms_ else None\n",
        "        self.unaligned = unaligned        \n",
        "        self.files_A = sorted(glob.glob(os.path.join(root, f\"{mode}A\", \"*.*\")))\n",
        "        self.files_B = sorted(glob.glob(os.path.join(root, f\"{mode}B\", \"*.*\")))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_A = Image.open(self.files_A[index % len(self.files_A)])\n",
        "        if self.unaligned:\n",
        "            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n",
        "        else:\n",
        "            image_B = Image.open(self.files_B[index % len(self.files_B)])\n",
        "        if image_A.mode != \"RGB\":\n",
        "            image_A = convert_to_rgb(image_A)\n",
        "        if image_B.mode != \"RGB\":\n",
        "            image_B = convert_to_rgb(image_B)\n",
        "        item_A = self.transform(image_A) if self.transform else image_A\n",
        "        item_B = self.transform(image_B) if self.transform else image_B\n",
        "        return {\"A\": item_A, \"B\": item_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Pkg4yedsxD4"
      },
      "outputs": [],
      "source": [
        "#transposing dimensions between plt and torch\n",
        "\n",
        "def show_img(img, size=10):\n",
        "    img = img / 2 + 0.5     \n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(size, size))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def to_img(x):    \n",
        "    x = x.view(x.size(0)*2, hp.channels, hp.img_size, hp.img_size)\n",
        "    return x\n",
        "\n",
        "def plot_output(path, x, y):\n",
        "    img = plt.imread(path)\n",
        "    plt.figure(figsize=(x,y))\n",
        "    plt.imshow(img)  \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HkBAriBtcxR"
      },
      "outputs": [],
      "source": [
        "#Image Buffer of 50 images\n",
        "\n",
        "class ReplayBuffer:\n",
        "    def __init__(self, max_size=50):\n",
        "        if max_size <= 0:\n",
        "            raise ValueError(\"max_size should be greater than 0.\")\n",
        "        self.max_size = max_size\n",
        "        self.buffer = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.buffer) < self.max_size:\n",
        "                self.buffer.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                # Randomly replace an existing element with the new element with a 0.5 probability.\n",
        "                if random.uniform(0, 1) > 0.5:\n",
        "                    idx = random.randint(0, self.max_size - 1)\n",
        "                    to_return.append(self.buffer[idx].clone())\n",
        "                    self.buffer[idx] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return torch.cat(to_return, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjoR9rpUtncG"
      },
      "outputs": [],
      "source": [
        "# Learning Rate and Decay\n",
        "\n",
        "class LambdaLR:\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        assert (n_epochs - decay_start_epoch) > 0, \"Error in class for learning rate\"\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        numerator = max(0, epoch + self.offset - self.decay_start_epoch)\n",
        "        denominator = self.n_epochs - self.decay_start_epoch\n",
        "        return 1.0 - numerator / denominator if denominator > 0 else 1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kHrPTVdtrDH"
      },
      "outputs": [],
      "source": [
        "# Convolution weights\n",
        "\n",
        "def initialize_conv_weights_normal(m):\n",
        "    if isinstance(m, torch.nn.Conv2d):\n",
        "        torch.nn.init.normal_(m.weight.data, mean=0.0, std=0.02)\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "    elif isinstance(m, torch.nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight.data, mean=1.0, std=0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkhSMjouuPLN"
      },
      "source": [
        "# Hyperparamters and Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R35-PtytgZW"
      },
      "outputs": [],
      "source": [
        "# HYPERPARAMETERS \n",
        "class Hyperparameters:\n",
        "    def __init__(self, **kwargs):\n",
        "        for key, value in kwargs.items():\n",
        "            setattr(self, key, value)\n",
        "\n",
        "hp = Hyperparameters(\n",
        "    epoch=0,\n",
        "    n_epochs=200,    \n",
        "    dataset_train_mode=\"train\",\n",
        "    dataset_test_mode=\"test\", \n",
        "    batch_size=4,        \n",
        "    lr=.0002,\n",
        "    decay_start_epoch=100,\n",
        "    b1=.5,\n",
        "    b2=0.999,\n",
        "    n_cpu=8,\n",
        "    img_size=128,\n",
        "    channels=3,\n",
        "    n_critic=5,\n",
        "    sample_interval=100,\n",
        "    num_residual_blocks=18,\n",
        "    lambda_cyc=10.0,\n",
        "    lambda_id=5.0\n",
        ")\n",
        "\n",
        "# Root Path for Google Drive\n",
        "root_path = '/content/drive/MyDrive/CycleGAN/Images/maps'\n",
        "save_path = '/content/drive/MyDrive/CycleGAN/Images/save'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COH_qG6FTIAr"
      },
      "outputs": [],
      "source": [
        "def save_img_samples(batches_done):\n",
        "    \"\"\"Saves a generated sample from the test set\"\"\"\n",
        "    print('batches_done ', batches_done)\n",
        "    imgs = next(iter(val_dataloader))\n",
        "    Gen_AB.eval()\n",
        "    Gen_BA.eval()\n",
        "    real_A = Variable(imgs[\"A\"].type(Tensor))\n",
        "    fake_B = Gen_AB(real_A)\n",
        "    real_B = Variable(imgs[\"B\"].type(Tensor))\n",
        "    fake_A = Gen_BA(real_B)\n",
        "    \n",
        "    for i in range(real_A.size(0)):\n",
        "        path = save_path + \"/real_A_%s.png\" % (i + batches_done*real_A.size(0))\n",
        "        save_image(real_A[i], path, normalize=True)\n",
        "\n",
        "    for i in range(fake_B.size(0)):\n",
        "        path = save_path + \"/fake_B_%s.png\" % (i + batches_done*fake_B.size(0))\n",
        "        save_image(fake_B[i], path, normalize=True)\n",
        "\n",
        "    for i in range(real_B.size(0)):\n",
        "        path = save_path + \"/real_B_%s.png\" % (i + batches_done*real_B.size(0))\n",
        "        save_image(real_B[i], path, normalize=True)\n",
        "\n",
        "    for i in range(fake_A.size(0)):\n",
        "        path = save_path + \"/fake_A_%s.png\" % (i + batches_done*fake_A.size(0))\n",
        "        save_image(fake_A[i], path, normalize=True)\n",
        "    \n",
        "    return path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Oe5M4eivQEu",
        "outputId": "c5f8468c-5907-4ac1-9829-cc157e91bcd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA\n"
          ]
        }
      ],
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if cuda else 'cpu')\n",
        "print(\"CUDA\" if cuda else \"No CUDA\")\n",
        "\n",
        "# Loss functions\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "input_shape = (hp.channels, hp.img_size, hp.img_size)\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "Gen_AB = GeneratorResNet(input_shape, hp.num_residual_blocks)\n",
        "Gen_BA = GeneratorResNet(input_shape, hp.num_residual_blocks)\n",
        "Disc_A = Discriminator(input_shape)\n",
        "Disc_B = Discriminator(input_shape)\n",
        "\n",
        "if cuda:\n",
        "    Gen_AB = Gen_AB.cuda()\n",
        "    Gen_BA = Gen_BA.cuda()\n",
        "    Disc_A = Disc_A.cuda()\n",
        "    Disc_B = Disc_B.cuda()\n",
        "    criterion_GAN.cuda()\n",
        "    criterion_cycle.cuda()\n",
        "    criterion_identity.cuda()\n",
        "\n",
        "Gen_AB.apply(initialize_conv_weights_normal)\n",
        "Gen_BA.apply(initialize_conv_weights_normal)\n",
        "Disc_A.apply(initialize_conv_weights_normal)\n",
        "Disc_B.apply(initialize_conv_weights_normal)\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbh9nUv8vm-g"
      },
      "outputs": [],
      "source": [
        "#OPTIMIZER\n",
        "\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(Gen_AB.parameters(), Gen_BA.parameters()), lr=hp.lr, betas=(hp.b1, hp.b2))\n",
        "optimizer_Disc_A = torch.optim.Adam(Disc_A.parameters(), lr=hp.lr, betas=(hp.b1, hp.b2))\n",
        "optimizer_Disc_B = torch.optim.Adam(Disc_B.parameters(), lr=hp.lr, betas=(hp.b1, hp.b2))\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_G, lr_lambda=LambdaLR(hp.n_epochs, hp.epoch, hp.decay_start_epoch).step\n",
        ")\n",
        "\n",
        "lr_scheduler_Disc_A = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_Disc_A, lr_lambda=LambdaLR(hp.n_epochs, hp.epoch, hp.decay_start_epoch).step\n",
        ")\n",
        "\n",
        "lr_scheduler_Disc_B = torch.optim.lr_scheduler.LambdaLR(\n",
        "    optimizer_Disc_B, lr_lambda=LambdaLR(hp.n_epochs, hp.epoch, hp.decay_start_epoch).step\n",
        ")\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apb9NoJ1xM_k"
      },
      "source": [
        "# Training Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhsnLuwDtNgr"
      },
      "outputs": [],
      "source": [
        "#initialising datasets, through dataloader\n",
        "\n",
        "transforms_ = [\n",
        "    transforms.Resize((hp.img_size, hp.img_size), Image.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "]\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    ImageDataset(root_path, mode=hp.dataset_train_mode, transforms_=transforms_),\n",
        "    batch_size=hp.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    ImageDataset(root_path, mode=hp.dataset_test_mode, transforms_=transforms_),\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maH3AeiEwmQi"
      },
      "outputs": [],
      "source": [
        "#Training Function\n",
        "\n",
        "def train(\n",
        "    Gen_BA,\n",
        "    Gen_AB,\n",
        "    Disc_A,\n",
        "    Disc_B,\n",
        "    train_dataloader,\n",
        "    n_epochs,\n",
        "    criterion_identity,\n",
        "    criterion_cycle,\n",
        "    lambda_cyc,\n",
        "    criterion_GAN,\n",
        "    optimizer_G,\n",
        "    fake_A_buffer,\n",
        "    fake_B_buffer,\n",
        "    optimizer_Disc_A,\n",
        "    optimizer_Disc_B,\n",
        "    Tensor,\n",
        "    sample_interval,\n",
        "    lambda_id,\n",
        "):\n",
        "    prev_time = time.time()\n",
        "    for epoch in range(hp.epoch, n_epochs):\n",
        "        for i, batch in enumerate(train_dataloader):\n",
        "            real_A = Variable(batch[\"A\"].type(Tensor))\n",
        "            real_B = Variable(batch[\"B\"].type(Tensor))\n",
        "            valid = Variable(\n",
        "                Tensor(np.ones((real_A.size(0), *Disc_A.output_shape))),\n",
        "                requires_grad=False,\n",
        "            )\n",
        "            fake = Variable(\n",
        "                Tensor(np.zeros((real_A.size(0), *Disc_A.output_shape))),\n",
        "                requires_grad=False,\n",
        "            )\n",
        "\n",
        "            #Generators\n",
        "            Gen_AB.train() \n",
        "            Gen_BA.train() \n",
        "            optimizer_G.zero_grad()\n",
        "            loss_identity = (criterion_identity(Gen_BA(real_A), real_A) + criterion_identity(Gen_AB(real_B), real_B))\n",
        "            loss_GAN = (criterion_GAN(Disc_B( Gen_AB(real_A)), valid) + criterion_GAN(Disc_A(Gen_BA(real_B)), valid))\n",
        "            loss_cycle = (criterion_cycle(Gen_BA(Gen_AB(real_A)), real_A) + criterion_cycle(Gen_AB(Gen_BA(real_B)), real_B))\n",
        "\n",
        "            loss_G = loss_GAN + lambda_cyc * loss_cycle + lambda_id * loss_identity\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            #discriminators\n",
        "            optimizer_Disc_A.zero_grad()\n",
        "            loss_real = criterion_GAN(Disc_A(real_A), valid)\n",
        "            fake_A_ = fake_A_buffer.push_and_pop(Gen_BA(real_B))\n",
        "            loss_fake = criterion_GAN(Disc_A(fake_A_.detach()), fake)\n",
        "            loss_Disc_A = (loss_real + loss_fake)\n",
        "            loss_Disc_A.backward()\n",
        "            optimizer_Disc_A.step()\n",
        "            optimizer_Disc_B.zero_grad()\n",
        "\n",
        "            loss_real = criterion_GAN(Disc_B(real_B), valid)\n",
        "            fake_B_ = fake_B_buffer.push_and_pop(Gen_AB(real_A))\n",
        "            loss_fake = criterion_GAN(Disc_B(fake_B_.detach()), fake)\n",
        "            loss_Disc_B = (loss_real + loss_fake)\n",
        "            loss_Disc_B.backward()\n",
        "            optimizer_Disc_B.step()\n",
        "            loss_D = (loss_Disc_A + loss_Disc_B)\n",
        "           \n",
        "            print(epoch,n_epochs,loss_G,loss_GAN,loss_cycle,loss_identity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYIOzj3MwnLk"
      },
      "outputs": [],
      "source": [
        "#TRAINING\n",
        "\n",
        "train(\n",
        "    Gen_BA = Gen_BA,\n",
        "    Gen_AB = Gen_AB,\n",
        "    Disc_A = Disc_A,\n",
        "    Disc_B = Disc_B,\n",
        "    train_dataloader = train_dataloader,\n",
        "    n_epochs = hp.n_epochs,\n",
        "    criterion_identity = criterion_identity,\n",
        "    criterion_cycle = criterion_cycle,\n",
        "    lambda_cyc = hp.lambda_cyc,\n",
        "    criterion_GAN = criterion_GAN,\n",
        "    optimizer_G = optimizer_G,\n",
        "    fake_A_buffer = fake_A_buffer,\n",
        "    fake_B_buffer = fake_B_buffer,\n",
        "    optimizer_Disc_A = optimizer_Disc_A,\n",
        "    optimizer_Disc_B = optimizer_Disc_B,\n",
        "    Tensor = Tensor,\n",
        "    sample_interval = hp.sample_interval,\n",
        "    lambda_id = hp.lambda_id,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "CPa0By15TkA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_fcn_scores(real_images, fake_images, num_classes=3, batch_size=64):\n",
        "    \n",
        "    # Load VGG16 model\n",
        "    vgg_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n",
        "    \n",
        "    # Preprocess real images and fake images for VGG16\n",
        "    real_images = tf.keras.applications.vgg16.preprocess_input(real_images)\n",
        "    fake_images = tf.keras.applications.vgg16.preprocess_input(fake_images)\n",
        "    \n",
        "    # Calculate features of real images and fake images\n",
        "    real_features = vgg_model.predict(real_images, batch_size=batch_size)\n",
        "    fake_features = vgg_model.predict(fake_images, batch_size=batch_size)\n",
        "    \n",
        "    # Calculate mean and covariance of real features\n",
        "    real_mean = np.mean(real_features, axis=0)\n",
        "    real_covariance = np.cov(np.transpose(real_features), bias=True)\n",
        "    \n",
        "    # Calculate mean and covariance of fake features\n",
        "    fake_mean = np.mean(fake_features, axis=0)\n",
        "    fake_covariance = np.cov(np.transpose(fake_features), bias=True)\n",
        "    \n",
        "    # Calculate squared Frobenius norm between real and fake features\n",
        "    squared_norm = np.linalg.norm(real_mean - fake_mean) ** 2\n",
        "    squared_trace = np.trace(real_covariance + fake_covariance - 2 * sqrtm(np.dot(real_covariance, fake_covariance)))\n",
        "    \n",
        "    # Calculate per-pixel accuracy\n",
        "    per_pixel_acc = np.sum(np.argmax(real_images, axis=-1) == np.argmax(fake_images, axis=-1)) / np.prod(real_images.shape[:-1])\n",
        "    \n",
        "    # Calculate per-class accuracy\n",
        "    per_class_acc = []\n",
        "    for c in range(num_classes):\n",
        "        real_class_mask = np.argmax(real_images, axis=-1) == c\n",
        "        fake_class_mask = np.argmax(fake_images, axis=-1) == c\n",
        "        class_acc = np.sum(real_class_mask == fake_class_mask) / np.sum(real_class_mask)\n",
        "        per_class_acc.append(class_acc)\n",
        "    \n",
        "    # Calculate class IOU losses\n",
        "    class_iou_losses = []\n",
        "    for c in range(num_classes):\n",
        "        real_class_mask = np.argmax(real_images, axis=-1) == c\n",
        "        fake_class_mask = np.argmax(fake_images, axis=-1) == c\n",
        "        intersection = np.sum(np.logical_and(real_class_mask, fake_class_mask))\n",
        "        union = np.sum(np.logical_or(real_class_mask, fake_class_mask))\n",
        "        iou_loss = 1 - intersection / union\n",
        "        class_iou_losses.append(iou_loss)\n",
        "    \n",
        "    return per_pixel_acc, per_class_acc, class_iou_losses\n",
        "\n",
        "# Example usage\n",
        "real_images = io.imread(\"/content/real_B_984000.png\")  \n",
        "fake_images = io.imread(\"/content/fake_A_984000.png\")\n",
        "per_pixel_acc, per_class_acc, class_iou_losses = calculate_fcn_scores(real_images, fake_images)\n",
        "print(\"FCN Score:\", per_pixel_acc, per_class_acc, class_iou_losses)\n"
      ],
      "metadata": {
        "id": "-AvAuB07T1rb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}